# Kafka Framework

Management of Kafka clusters in DCOS

<!-- TOC START: generated by generate-md-toc.py, do not edit -->

- [Overview](#overview)
  - [Benefits](#benefits)
  - [Features](#features)
  - [Related Services](#related-services)
- [Quick Start](#quick-start)
- [Installation and Customization](#installation-and-customization)
  - [Default install configuration](#default-install-configuration)
  - [Custom install configuration](#custom-install-configuration)
  - [Uninstall](#uninstall)
  - [Changing configuration in flight](#changing-configuration-in-flight)
- [Configuration Options](#configuration-options)
  - [Framework Name](#framework-name)
  - [Broker Count](#broker-count)
  - [Enable Persistent Volumes](#enable-persistent-volumes)
  - [Configure Broker Placement Strategy](#configure-broker-placement-strategy)
- [Upgrading Software](#upgrading-software)
- [Connecting Clients](#connecting-clients)
- [Handling Errors](#handling-errors)
  - [Configuration Update Errors](#configuration-update-errors)
  - [Software Maintenance Errors](#software-maintenance-errors)
  - [Status Errors](#status-errors)
  - [Replacing a Permanently Failed Server](#replacing-a-permanently-failed-server)
- [Limitations](#limitations)
  - [Configurations](#configurations)
  - [Brokers](#brokers)
  - [Security](#security)
- [Cluster Maintenance APIs](#cluster-maintenance-apis)
  - [Connection Information](#connection-information)
  - [Broker Operations](#broker-operations)
    - [Add Broker](#add-broker)
    - [Remove Broker](#remove-broker)
    - [List All Brokers](#list-all-brokers)
    - [View Broker Details](#view-broker-details)
    - [Restart Single Broker](#restart-single-broker)
    - [Restart All Brokers](#restart-all-brokers)
  - [Topic Operations](#topic-operations)
    - [List Topics](#list-topics)
    - [Create Topic](#create-topic)
    - [View Topic Details](#view-topic-details)
    - [View Topic Offsets](#view-topic-offsets)
    - [Alter Topic Partition Count](#alter-topic-partition-count)
    - [Alter Topic Config Value](#alter-topic-config-value)
    - [Delete/Unset Topic Config Value](#deleteunset-topic-config-value)
    - [Run Producer Test on Topic](#run-producer-test-on-topic)
    - [Delete Topic](#delete-topic)
    - [List Under Replicated Partitions](#list-under-replicated-partitions)
    - [List Unavailable Partitions](#list-unavailable-partitions)
- [TODO [API for ACL changes](https://kafka.apache.org/documentation.html#security_authz_examples)? (kafka-acls.sh)](#todo-api-for-acl-changeshttpskafkaapacheorgdocumentationhtmlsecurity_authz_examples-kafka-aclssh)
- [Development](#development)

<!-- TOC END: generated by generate-md-toc.py, do not edit -->

## Overview

DCOS Kafka Service is an automated service framework that make it easy to deploy and manage Apache Kafka on Mesosphere DCOS. Apache Kafka is a distributed high throughput publish-subscribe messaging system with strong durability with ordering guarantees. For more information on Apache Kafka, see the Apache Kafka [documentation](http://kafka.apache.org/documentation.html). With DCOS Kafka Service, you get direct access to the Kafka API so that existing can interoperate. You can configure and install Kafka in less than minutes. Multiple Kafka clusters can be installed to DCOS and managed independently, enabling IT to offer Kafka as a managed service to the organization. Kafka clusters are highly available, e, fault tolerant, and highly durable. DCOS Kafka Service eliminates nearly all of the complexity traditionally associated with managing an Kafka cluster.

### Benefits

DCOS Kafka Service offers the following benefits of a semi-managed service:

- Easy installation
- Multiple Kafka clusters
- Elastic scaling of brokers
- Replication for high availability
- Kafka cluster and broker monitoring

### Features

DCOS Kafka Service provides the following features:

- Single command installation for rapid provisioning
- Multiple clusters for multiple tenancy with DCOS
- Runtime configuration and software update for high availability
- Storage volumes for enhanced data durability, known as Mesos Dynamic Reservations and Persistent Volumes
- Integration with syslog-compatible logging services for diagnostics and troubleshooting
- Integration with statsd-compatible metrics services for capacity and performance monitoring

### Related Services

- [DCOS Spark Service](https://docs.mesosphere.com/manage-service/spark)

## Quick Start

- Step 1. Install [dcos-cli](https://github.com/mesosphere/dcos-cli).

- Step 2. Install a Kafka cluster.

``` bash
$ dcos package install kafka # framework name defaults to 'kafka0'
```

- Step 3. Create a new topic.

``` bash
$ dcos kafka topic create topic1 --partitions 3 --replication 3
```

- Step 4. Read and write data to a topic.

**TODO** a couple one-liners using e.g., `bin/kafka-console-[producer|consumer].sh` to send/get data. see also [Connecting clients](#connecting-clients)

- Step 5. Mark a topic for deletion.

``` bash
$ dcos kafka topic describe topic1
```

- Step 6. Uninstall the cluster.

``` bash
$ dcos package uninstall --app-id=kafka0 kafka
```

## Installation and Customization

### Default install configuration

To start a basic test cluster with three brokers, run the following command with dcos-cli:

``` bash
$ dcos package install kafka
```

By default, this will create a new Kafka cluster named `kafka0`. Two clusters cannot share the same name, so installing additional clusters beyond the default cluster would require [customizing the `framework-name` at install time](#custom-install-configuration) for each additional instance.

All `dcos kafka` CLI commands have a `--framework-name` argument allowing the user to specify which Kafka instance to query, which defaults to `kafka0`. The default value for `--framework-name` can be customized via the DCOS CLI configuration:

``` bash
$ dcos config set kafka.framework_name new_default_name
```

The default cluster is intended for testing/development. Additional customization would be needed before it can be considered suitable for production use. Running clusters may be [re-configured in-place using Marathon](#changing-configuration-in-flight).

### Custom install configuration

The defaults may be customized by creating a JSON file, then passing it to `dcos package install` using the `--options parameter`. For example:

Sample JSON options file named `sample-kafka.json`:
``` json
{
  "kafka": {
    "broker-count": 10,
    "framework-name": "sample-kafka",
    "pv": true,
    "placement-strategy": "NODE"
  }
}
```

Creating a cluster using `sample-kafka.json`:
``` bash
$ dcos package install --options=sample-kafka.json kafka
```

See [Configuration Options](#configuration-options) for a list of available fields which can be customized via an options JSON file when the Kafka cluster is created.

### Uninstall

Uninstalling a cluster is also straightforward. Replace `kafka0` with the name of the kafka instance to be uninstalled.

``` bash
$ dcos package uninstall --app-id=kafka0 kafka
```

The instance will still be present in zookeeper at `/[framework_name]`, e.g., `/kafka0`. To completely clear the configuration, the zookeeper node must be removed.

### Changing configuration in flight

Once the cluster is already up and running, it may be customized in-place. The Kafka Scheduler will be running as a Marathon process, and can be reconfigured by changing values within Marathon.

1. View your Marathon dashboard at `http://$DCOS_URI/marathon`
2. In the list of `Applications`, click the name of the Kafka framework to be updated.
3. Within the Kafka instance details view, click the `Configuration` tab, then click the `Edit` button.
4. In the dialog that appears, expand the `Environment Variables` section and update any field(s) to their desired value(s). For example, to [increase the number of Brokers](#broker-count), edit the value for `BROKER_COUNT`. Do not edit the value for `FRAMEWORK_NAME`.
5. Click `Change and deploy configuration` to apply any changes and cleanly reload the Kafka Framework scheduler. The Kafka cluster itself will persist across the change.

See [Configuration Options](#configuration-options) for a list of available fields which can be customized via Marathon while the Kafka cluster is running.

## Configuration Options

The following describes commonly used features of the Kafka framework and how to configure them. View the [default `config.json` in DCOS Universe](https://github.com/mesosphere/universe/tree/version-1.x/repo/packages/K/kafka) to see an enumeration of all possible options.

### Framework Name

The name of this Kafka instance in DCOS. This is the only option that cannot be changed once the Kafka cluster is started; it can only be configured via the `dcos-cli --options` flag when first creating the Kafka instance.

- **In dcos-cli options.json**: `framework-name` = string (default: `kafka0`)
- **In Marathon**: The Framework Name cannot be changed after the cluster has started.

### Broker Count

Configure the number of brokers running in a given Kafka cluster. The default count at installation is three brokers.

- **In dcos-cli options.json**: `broker-count` = integer (default: `3`)
- **In Marathon**: `BROKER_COUNT` = integer

### Enable Persistent Volumes

By default Kafka Brokers will use the sandbox available to Mesos Tasks for storing data. This storage goes away on Task failure. So if a Broker crashes the data on it is lost forever. This is fine for dev environments. In production environments Kafka should be deployed with the following option enabled:

- **In dcos-cli options.json**: `pv` = boolean (default: `false`)
- **In Marathon**: `BROKER_PV` = `TRUE` or `FALSE`

### Configure Broker Placement Strategy

`ANY` will allow brokers to be placed on any node with sufficient resources, while `NODE` will ensure that all brokers within a given Kafka cluster are never colocated on the same node. In the future, this may also prevent brokers across multiple Kafka clusters from colocating, but this isn't yet the case.

- **In dcos-cli options.json**: `placement-strategy` = `ANY` or `NODE` (default: `ANY`)
- **In Marathon**: `PLACEMENT_STRATEGY` = `ANY` or `NODE`

## Upgrading Software

**TODO** once implemented: guide for updating kafka process and/or framework itself

## Connecting Clients

**TODO** step by step for talking to a DCOS-hosted Kafka instance using `bin/kafka-console-producer.sh` and `bin/kafka-console-consumer.sh` as an example

## Handling Errors

### Configuration Update Errors

**TODO** How to handle configuration input validation errors

**TODO** How to handle errors when applying configuration to a running service

### Software Maintenance Errors

**TODO** How to handle errors when updating software

### Status Errors

**TODO** how to handle status = error

**TODO** how to handle status = warning

### Replacing a Permanently Failed Server

**TODO** How to tell the scheduler a specific Mesos Agent is dead and never coming back

## Limitations

### Configurations

**TODO** Settings that can only be set at install time

**TODO** Pitfalls of managing configurations outside of the framework

### Brokers

**TODO** Max count (if any)

### Security

**TODO** describe how someone could configure Kafka 0.9's beta security features (or specify that they're not supported?): data encryption, client authentication over SSL/SASL, broker authentication with ZK...

## Cluster Maintenance APIs

For ongoing maintenance of the Kafka cluster itself, the Kafka Framework exposes an HTTP API whose structure is designed to roughly match the tools provided by the Kafka distribution, such as `bin/kafka-topics.sh`.

The examples here provide equivalent commands using both `[dcos-cli](https://github.com/mesosphere/dcos-cli)` (with the `kafka` CLI module installed) and `curl`. These examples assume a service named `kafka0` (the default), and the `curl` examples assume a DCOS host of `$DCOS_URI`. Replace these with appropriate values as needed.

The `dcos kafka` CLI commands have a `--framework-name` argument allowing the user to specify which Kafka instance to query. The value defaults to `kafka0`, so it's technically redundant to specify `--framework-name=kafka0` in these examples. The default value for `--framework-name` can be customized via the DCOS CLI configuration:

``` bash
$ dcos config set kafka.framework_name new_default_name
```

### Connection Information

Kafka comes with many useful tools of its own. They often require either Zookeeper connection information, or the list of Broker endpoints. This information can be retrieved in an easily consumable formation from the `/connection` endpoint as below.

``` bash
$ curl -X GET "$DCOS_URI/service/kafka0/v1/connection"
GET /service/kafka0/v1/connection HTTP/1.1
[...]

{
    "brokers": [
        "10.0.0.1:9092",
        "10.0.0.2:9093",
        "10.0.0.3:9094"
    ],
    "zookeeper": "master.mesos:2181/kafka0"
}
```

### Broker Operations

#### Add Broker

Increase the `BROKER_COUNT` value via Marathon. New brokers should start automatically.

#### Remove Broker

Broker removal is currently a manual process.

**TODO**: Specify step-by-step for manually removing broker(s)

#### List All Brokers

``` bash
$ dcos kafka --framework-name=kafka0 broker list
{
    "brokers": [
        "0",
        "1",
        "2"
    ]
}
```

``` bash
$ curl -X GET "$DCOS_URI/service/kafka0/v1/brokers"
GET /service/kafka0/v1/brokers HTTP/1.1
[...]

{
    "brokers": [
        "0",
        "1",
        "2"
    ]
}
```
#### View Broker Details

``` bash
$ dcos kafka --framework-name=kafka0 broker describe 0
{
    "endpoints": [
        "PLAINTEXT://w1.dcos:9092"
    ],
    "host": "w1.dcos",
    "jmx_port": -1,
    "port": 9092,
    "timestamp": "1454462821420",
    "version": 2
}

```

``` bash
$ curl -X GET "$DCOS_URI/service/kafka0/v1/brokers/0"
GET /service/kafka0/v1/brokers/0 HTTP/1.1
[...]

{
    "endpoints": [
        "PLAINTEXT://worker12398:9092"
    ],
    "host": "worker12398",
    "jmx_port": -1,
    "port": 9092,
    "timestamp": "1453854226816",
    "version": 2
}
```

#### Restart Single Broker

``` bash
$ dcos kafka --framework-name=kafka0 broker restart 0
[
    "broker-0__9c426c50-1087-475c-aa36-cd00d24ccebb"
]
```

``` bash
$ curl -X PUT "$DCOS_URI/service/kafka0/v1/brokers/0"
PUT /service/kafka0/v1/brokers/0 HTTP/1.1
[...]

[
    "broker-0__9c426c50-1087-475c-aa36-cd00d24ccebb"
]
```

#### Restart All Brokers

``` bash
$ curl -X PUT $DCOS_URI/service/kafka0/v1/brokers
PUT /service/kafka0/v1/brokers HTTP/1.1
[...]

[
    "broker-1__759c9fc2-3890-4921-8db8-c87532b1a033",
    "broker-2__0b444104-e210-4b78-8d19-f8938b8761fd",
    "broker-0__9c426c50-1087-475c-aa36-cd00d24ccebb"
]
```

### Topic Operations

These operations mirror what's available using `bin/kafka-topics.sh`.

#### List Topics

``` bash
$ dcos kafka --framework-name=kafka0 topic list
[
    "topic1",
    "topic0"
]
```

``` bash
$ curl -X GET "$DCOS_URI/service/kafka0/v1/topics"
GET /service/kafka0/v1/topics HTTP/1.1
[...]

[
    "topic1",
    "topic0"
]
```

#### Create Topic

``` bash
$ dcos kafka --framework-name=kafka0 topic create topic1 --partitions=3 --replication=3
{
    "exit_code": 0,
    "stderr": "",
    "stdout": "Created topic \"topic1\".\n"
}
```

``` bash
$ curl -X POST "$DCOS_URI/service/kafka0/v1/topics?name=topic1&partitions=3&replication=3"
POST /service/kafka0/v1/topics?replication=3&name=topic1&partitions=3 HTTP/1.1
[...]

{
    "exit_code": 0,
    "stderr": "",
    "stdout": "Created topic \"topic1\".\n"
}
```

#### View Topic Details

``` bash
$ dcos kafka --framework-name=kafka0 topic describe topic1
{
    "partitions": [
        {
            "0": {
                "controller_epoch": 1,
                "isr": [
                    0,
                    1,
                    2
                ],
                "leader": 0,
                "leader_epoch": 0,
                "version": 1
            }
        },
        {
            "1": {
                "controller_epoch": 1,
                "isr": [
                    1,
                    2,
                    0
                ],
                "leader": 1,
                "leader_epoch": 0,
                "version": 1
            }
        },
        {
            "2": {
                "controller_epoch": 1,
                "isr": [
                    2,
                    0,
                    1
                ],
                "leader": 2,
                "leader_epoch": 0,
                "version": 1
            }
        }
    ]
}
```

``` bash
$ curl -X GET "$DCOS_URI/service/kafka0/v1/topics/topic1"
GET /service/kafka0/v1/topics/topic1 HTTP/1.1
[...]

{
    "partitions": [
        {
            "0": {
                "controller_epoch": 1,
                "isr": [
                    0,
                    1,
                    2
                ],
                "leader": 0,
                "leader_epoch": 0,
                "version": 1
            }
        },
        {
            "1": {
                "controller_epoch": 1,
                "isr": [
                    1,
                    2,
                    0
                ],
                "leader": 1,
                "leader_epoch": 0,
                "version": 1
            }
        },
        {
            "2": {
                "controller_epoch": 1,
                "isr": [
                    2,
                    0,
                    1
                ],
                "leader": 2,
                "leader_epoch": 0,
                "version": 1
            }
        }
    ]
}
```

#### View Topic Offsets

``` bash
$ dcos kafka --framework-name=kafka0 topic offsets topic1
GET /service/kafka0/v1/topics/topic1/offsets HTTP/1.1
[...]

[
    {
        "2": "334"
    },
    {
        "1": "333"
    },
    {
        "0": "333"
    }
]
```

``` bash
$ curl -X "$DCOS_URI/service/kafka0/v1/topics/topic1/offsets"
GET /service/kafka0/v1/topics/topic1/offsets HTTP/1.1
[...]

[
    {
        "2": "334"
    },
    {
        "1": "333"
    },
    {
        "0": "333"
    }
]
```

#### Alter Topic Partition Count

``` bash
$ dcos kafka --framework-name=kafka0 topic partitions topic1 2

{
    "exit_code": 0,
    "stderr": "",
    "stdout": "WARNING: If partitions are increased for a topic that has a key, the partition logic or ordering of the messages will be affected\nAdding partitions succeeded!\n"
}
```

``` bash
$ curl -X PUT "$DCOS_URI/service/kafka0/v1/topics/topic1?operation=partitions&partitions=2"
PUT /service/kafka0/v1/topics/topic1?operation=partitions&partitions=2 HTTP/1.1
[...]

{
    "exit_code": 0,
    "stderr": "",
    "stdout": "WARNING: If partitions are increased for a topic that has a key, the partition logic or ordering of the messages will be affected\nAdding partitions succeeded!\n"
}
```

#### Alter Topic Config Value

``` bash
$ dcos kafka --framework-name=kafka0 topic config topic1 cleanup.policy compact
```

``` bash
$ curl -vX PUT "$DCOS_URI/service/kafka0/v1/topics/topic1?operation=config&key=cleanup.policy&value=compact"
PUT /service/kafka0/v1/topics/topic1?operation=config&key=cleanup.policy&value=compact HTTP/1.1
[...]

{
    "exit_code": 0,
    "stderr": "",
    "stdout": "Updated config for topic \"topic0\".\n"
}
```

#### Delete/Unset Topic Config Value

``` bash
$ dcos kafka --framework-name=kafka0 topic delete_config --key=cleanup.policy
```

``` bash
$ curl -vX PUT "$DCOS_URI/service/kafka0/v1/topics/topic1?operation=deleteConfig&key=cleanup.policy"
```

#### Run Producer Test on Topic

``` bash
$ dcos kafka --framework-name=kafka0 topic producer_test topic1 10

{
    "exit_code": 0,
    "stderr": "",
    "stdout": "10 records sent, 70.422535 records/sec (0.07 MB/sec), 24.20 ms avg latency, 133.00 ms max latency, 13 ms 50th, 133 ms 95th, 133 ms 99th, 133 ms 99.9th.\n"
}
```

``` bash
$ curl -X PUT "$DCOS_URI/service/kafka0/v1/topics/topic1?operation=producer-test&messages=10"
PUT /service/kafka0/v1/topics/topic1?operation=producer-test&messages=10 HTTP/1.1
[...]

{
    "exit_code": 0,
    "stderr": "",
    "stdout": "10 records sent, 70.422535 records/sec (0.07 MB/sec), 24.20 ms avg latency, 133.00 ms max latency, 13 ms 50th, 133 ms 95th, 133 ms 99th, 133 ms 99.9th.\n"
}
```

#### Delete Topic

``` bash
$ dcos kafka --framework-name=kafka0 topic delete topic1

{
    "exit_code": 0,
    "stderr": "",
    "stdout": "Topic topic1 is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\n"
}
```

``` bash
$ curl -X DELETE "$DCOS_URI/service/kafka0/v1/topics/topic1"
DELETE /service/kafka0/v1/topics/topic1?operation=delete HTTP/1.1
[...]

{
    "exit_code": 0,
    "stderr": "",
    "stdout": "Topic topic1 is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\n"
}
```

#### List Under Replicated Partitions

``` bash
$ dcos kafka --framework-name=kafka0 topic under_replicated_partitions

{
    "exit_code": 0,
    "stderr": "",
    "stdout": ""
}
```

``` bash
$ curl -X "$DCOS_URI/service/kafka0/v1/topics/under_replicated_partitions"
GET /service/kafka0/v1/topics/under_replicated_partitions HTTP/1.1
[...]

{
    "exit_code": 0,
    "stderr": "",
    "stdout": ""
}
```

#### List Unavailable Partitions

``` bash
$ dcos kafka --framework-name=kafka0 topic unavailable_partitions

{
    "exit_code": 0,
    "stderr": "",
    "stdout": ""
}
```

``` bash
$ curl -X "$DCOS_URI/service/kafka0/v1/topics/unavailable_partitions"
GET /service/kafka0/v1/topics/unavailable_partitions HTTP/1.1
[...]

{
    "exit_code": 0,
    "stderr": "",
    "stdout": ""
}
```

## TODO [API for ACL changes](https://kafka.apache.org/documentation.html#security_authz_examples)? (kafka-acls.sh)

## Development

See [CONTRIBUTING.md](CONTRIBUTING.md) for the development guide.

