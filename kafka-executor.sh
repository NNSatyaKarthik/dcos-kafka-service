export PATH=PATH:$MESOS_SANDBOX/jre/bin
#!/bin/sh

# This is the Executor for the Kafka Mesos Framework. It's small because it doesn't do much!
# It does some minor changes to the Kafka classpath and configs, then runs Kafka itself.

echo "--- STARTING KAFKA EXECUTOR: $0 ---"

export PATH=$PATH:$MESOS_SANDBOX/jre/bin

echo "--- START ENV"
env
echo "--- END ENV"

# Find the Kafka distribution.
EXECUTOR_ROOT="$(dirname $0)"
KAFKA_DISTRIBUTION_SEARCH_PATTERN="$MESOS_SANDBOX/kafka_*/"
KAFKA_DISTRIBUTION_ROOT="$(ls -d ${KAFKA_DISTRIBUTION_SEARCH_PATTERN})"
if [ -d "${KAFKA_DISTRIBUTION_ROOT}" ]; then
    echo "Kafka distribution found: ${KAFKA_DISTRIBUTION_ROOT}"
else
    echo "Kafka distribution not found with search pattern, exiting immediately!: ${KAFKA_DISTRIBUTION_SEARCH_PATTERN}"
    exit 1
fi

KAFKA_SERVER_PROPERTIES_PATH="${KAFKA_DISTRIBUTION_ROOT}config/server.properties"

# If the package includes a library overlay, apply it onto Kafka's /libs directory
LIB_OVERLAY_PATH="${EXECUTOR_ROOT}/libs"
if [ -d "${EXECUTOR_ROOT}/libs" ]; then
    echo "Copying library overlay onto Kafka classpath..."
    echo "--- BEGIN COPY ${LIB_OVERLAY_PATH} => ${KAFKA_DISTRIBUTION_ROOT}"
    cp -vR ${LIB_OVERLAY_PATH} ${KAFKA_DISTRIBUTION_ROOT}
    if [ $? -ne 0 ]; then
        echo "Failed to copy library overlays from ${LIB_OVERLAY_PATH} to ${KAFKA_DISTRIBUTION_ROOT}. Exiting immediately!"
        exit 1
    fi
    echo "--- END COPY ${LIB_OVERLAY_PATH} => ${KAFKA_DISTRIBUTION_ROOT}"
fi

# Updates to server.properties (values at end of file override earlier values)
#TODO: How should zookeeper host:port be stored here?
KAFKA_LOG_PATH="${KAFKA_DISTRIBUTION_ROOT}logs"
cat >> "${KAFKA_SERVER_PROPERTIES_PATH}" <<EOF

# The following is all autogenerated by the Kafka Mesos Executor

# Override Zookeeper host:port (provided by Scheduler)
zookeeper.connect=${KAFKA_FWK_ZK_ENDPOINT}
# Override default broker id value with env value (provided by Scheduler)
broker.id=${KAFKA_FWK_BROKER_ID}

# Override default log path to stay within container (instead of /tmp/kafka-logs)
log.dirs=${KAFKA_LOG_PATH}

EOF

# If runtime env provides a statsd endpoint, append a basic statsd config to server.properties
if [ -n "${STATSD_UDP_HOST}" -a -n "${STATSD_UDP_PORT}" ]; then
    echo "Statsd endpoint found in environment, enabling in server.properties: ${STATSD_UDP_HOST}:${STATSD_UDP_PORT}..."
    cat >> "${KAFKA_SERVER_PROPERTIES_PATH}" <<EOF

# Enable StatsD export
kafka.metrics.reporters=com.airbnb.kafka.KafkaStatsdMetricsReporter
external.kafka.statsd.reporter.enabled=true
external.kafka.statsd.host=${STATSD_UDP_HOST}
external.kafka.statsd.port=${STATSD_UDP_PORT}
external.kafka.statsd.metrics.exclude_regex=""
EOF
    echo "--- START ${KAFKA_SERVER_PROPERTIES_PATH}"
    cat ${KAFKA_SERVER_PROPERTIES_PATH}
    echo "--- END ${KAFKA_SERVER_PROPERTIES_PATH}"
fi

# Start kafka itself.
# TODO append any other optimizations (eg heap sizes) here!!
CMD="${KAFKA_DISTRIBUTION_ROOT}bin/kafka-server-start.sh ${KAFKA_SERVER_PROPERTIES_PATH}"

echo "Starting Kafka: ${CMD} (from ${EXECUTOR_ROOT})"
echo "--- START KAFKA ---"
${CMD}
RET=$?
echo "--- END KAFKA ---"
echo "Kafka exited with code ${RET}. Shutting down."
exit $RET
